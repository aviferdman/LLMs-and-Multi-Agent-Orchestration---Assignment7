{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a26f3ff",
   "metadata": {},
   "source": [
    "## Section 1: Data Loading & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c127ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('colorblind')  # Colorblind-friendly palette\n",
    "\n",
    "print('Libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daf382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tournament data\n",
    "data_dir = Path('../doc/results')\n",
    "\n",
    "# Try to load aggregated data\n",
    "try:\n",
    "    aggregated_df = pd.read_csv(data_dir / 'aggregated_data.csv')\n",
    "    print(f'Aggregated data loaded: {len(aggregated_df)} records')\n",
    "    print(f'Columns: {list(aggregated_df.columns)}')\n",
    "except FileNotFoundError:\n",
    "    print('aggregated_data.csv not found, creating sample data')\n",
    "    aggregated_df = pd.DataFrame({\n",
    "        'player': ['P01', 'P02', 'P03', 'P04'],\n",
    "        'strategy': ['Random', 'Pattern', 'History', 'Mixed'],\n",
    "        'wins': [45, 52, 58, 55],\n",
    "        'losses': [55, 48, 42, 45],\n",
    "        'total_matches': [100, 100, 100, 100],\n",
    "        'win_rate': [0.45, 0.52, 0.58, 0.55]\n",
    "    })\n",
    "\n",
    "# Try to load raw data\n",
    "try:\n",
    "    raw_df = pd.read_csv(data_dir / 'raw_data.csv')\n",
    "    print(f'\\nRaw data loaded: {len(raw_df)} records')\n",
    "except FileNotFoundError:\n",
    "    print('raw_data.csv not found, creating sample data')\n",
    "    np.random.seed(42)\n",
    "    raw_df = pd.DataFrame({\n",
    "        'match_id': range(1, 201),\n",
    "        'player1': np.random.choice(['P01', 'P02', 'P03', 'P04'], 200),\n",
    "        'player2': np.random.choice(['P01', 'P02', 'P03', 'P04'], 200),\n",
    "        'winner': np.random.choice(['player1', 'player2'], 200),\n",
    "        'rounds': np.random.randint(5, 15, 200),\n",
    "        'duration_ms': np.random.randint(100, 500, 200)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a888bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore aggregated data\n",
    "print('=== Aggregated Data Summary ===')\n",
    "print(aggregated_df.describe())\n",
    "print('\\n=== Data Types ===')\n",
    "print(aggregated_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa60844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the aggregated data\n",
    "aggregated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9426915",
   "metadata": {},
   "source": [
    "## Section 2: Statistical Analysis with Interpretations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41683a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confidence_interval(wins, total, confidence=0.95):\n",
    "    \"\"\"Calculate confidence interval for win rate.\"\"\"\n",
    "    p = wins / total\n",
    "    z = stats.norm.ppf((1 + confidence) / 2)\n",
    "    se = np.sqrt(p * (1 - p) / total)\n",
    "    return p - z * se, p + z * se\n",
    "\n",
    "def cohens_d(group1, group2):\n",
    "    \"\"\"Calculate Cohen's d effect size.\"\"\"\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)\n",
    "    pooled_std = np.sqrt(((n1-1)*var1 + (n2-1)*var2) / (n1+n2-2))\n",
    "    return (np.mean(group1) - np.mean(group2)) / pooled_std\n",
    "\n",
    "print('Statistical functions defined successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14fe642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confidence intervals for each player\n",
    "print('=== Win Rate Confidence Intervals (95%) ===')\n",
    "print()\n",
    "\n",
    "for _, row in aggregated_df.iterrows():\n",
    "    ci_low, ci_high = calculate_confidence_interval(row['wins'], row['total_matches'])\n",
    "    print(f\"{row['player']} ({row['strategy']}):\")\n",
    "    print(f\"  Win Rate: {row['win_rate']:.1%}\")\n",
    "    print(f\"  95% CI: [{ci_low:.1%}, {ci_high:.1%}]\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e886fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform pairwise t-tests with Bonferroni correction\n",
    "print('=== Pairwise Comparisons with Bonferroni Correction ===')\n",
    "print()\n",
    "\n",
    "strategies = aggregated_df['strategy'].values\n",
    "win_rates = aggregated_df['win_rate'].values\n",
    "n_comparisons = len(strategies) * (len(strategies) - 1) // 2\n",
    "alpha_corrected = 0.05 / n_comparisons\n",
    "\n",
    "print(f'Number of comparisons: {n_comparisons}')\n",
    "print(f'Corrected alpha level: {alpha_corrected:.4f}')\n",
    "print()\n",
    "\n",
    "results = []\n",
    "for i in range(len(strategies)):\n",
    "    for j in range(i+1, len(strategies)):\n",
    "        diff = win_rates[i] - win_rates[j]\n",
    "        # Using normal approximation for proportion comparison\n",
    "        n = aggregated_df.iloc[i]['total_matches']\n",
    "        p1, p2 = win_rates[i], win_rates[j]\n",
    "        pooled_p = (p1 + p2) / 2\n",
    "        se = np.sqrt(2 * pooled_p * (1 - pooled_p) / n)\n",
    "        z_stat = diff / se if se > 0 else 0\n",
    "        p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
    "        \n",
    "        sig = ''\n",
    "        if p_value < 0.001: sig = '***'\n",
    "        elif p_value < 0.01: sig = '**'\n",
    "        elif p_value < 0.05: sig = '*'\n",
    "        \n",
    "        results.append({\n",
    "            'Comparison': f'{strategies[i]} vs {strategies[j]}',\n",
    "            'Diff': f'{diff:+.1%}',\n",
    "            'z-stat': f'{z_stat:.2f}',\n",
    "            'p-value': f'{p_value:.4f}',\n",
    "            'Sig': sig\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d5576f",
   "metadata": {},
   "source": [
    "### Interpretation of Statistical Results\n",
    "\n",
    "The pairwise comparisons show the differences in win rates between strategies.\n",
    "\n",
    "**Significance markers:**\n",
    "- \\* p < 0.05 (significant)\n",
    "- \\*\\* p < 0.01 (highly significant)\n",
    "- \\*\\*\\* p < 0.001 (very highly significant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8225c6ee",
   "metadata": {},
   "source": [
    "## Section 3: Interactive Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e269bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create publication-quality win rate chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=150)\n",
    "\n",
    "# Calculate error bars (95% CI)\n",
    "errors = []\n",
    "for _, row in aggregated_df.iterrows():\n",
    "    ci_low, ci_high = calculate_confidence_interval(row['wins'], row['total_matches'])\n",
    "    errors.append((row['win_rate'] - ci_low, ci_high - row['win_rate']))\n",
    "\n",
    "colors = sns.color_palette('colorblind', n_colors=len(aggregated_df))\n",
    "\n",
    "bars = ax.bar(aggregated_df['strategy'], \n",
    "              aggregated_df['win_rate'] * 100,\n",
    "              yerr=np.array(errors).T * 100,\n",
    "              capsize=5,\n",
    "              color=colors,\n",
    "              edgecolor='black',\n",
    "              linewidth=1.2)\n",
    "\n",
    "# Add value labels\n",
    "for bar, rate in zip(bars, aggregated_df['win_rate']):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 3,\n",
    "            f'{rate:.1%}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add baseline\n",
    "ax.axhline(y=50, color='red', linestyle='--', alpha=0.7, label='Random Baseline (50%)')\n",
    "\n",
    "ax.set_xlabel('Strategy', fontsize=14)\n",
    "ax.set_ylabel('Win Rate (%)', fontsize=14)\n",
    "ax.set_title('Player Strategy Win Rates with 95% Confidence Intervals', fontsize=16)\n",
    "ax.set_ylim(0, 100)\n",
    "ax.legend(loc='upper right')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../doc/results/strategy_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ea2e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create win/loss distribution chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=150)\n",
    "\n",
    "x = np.arange(len(aggregated_df))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, aggregated_df['wins'], width, label='Wins', color='#2ecc71', edgecolor='black')\n",
    "bars2 = ax.bar(x + width/2, aggregated_df['losses'], width, label='Losses', color='#e74c3c', edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('Strategy', fontsize=14)\n",
    "ax.set_ylabel('Number of Matches', fontsize=14)\n",
    "ax.set_title('Win/Loss Distribution by Strategy', fontsize=16)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(aggregated_df['strategy'])\n",
    "ax.legend()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars1:\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "            f'{int(bar.get_height())}', ha='center', va='bottom', fontsize=10)\n",
    "for bar in bars2:\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "            f'{int(bar.get_height())}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../doc/results/win_loss_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958f6cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap for pairwise comparison\n",
    "n_strategies = len(strategies)\n",
    "comparison_matrix = np.zeros((n_strategies, n_strategies))\n",
    "\n",
    "for i in range(n_strategies):\n",
    "    for j in range(n_strategies):\n",
    "        if i == j:\n",
    "            comparison_matrix[i, j] = 0\n",
    "        else:\n",
    "            comparison_matrix[i, j] = win_rates[i] - win_rates[j]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=150)\n",
    "sns.heatmap(comparison_matrix * 100, \n",
    "            annot=True, \n",
    "            fmt='.1f',\n",
    "            cmap='RdYlGn',\n",
    "            center=0,\n",
    "            xticklabels=strategies,\n",
    "            yticklabels=strategies,\n",
    "            ax=ax,\n",
    "            cbar_kws={'label': 'Win Rate Difference (%)'})\n",
    "\n",
    "ax.set_title('Strategy Comparison Heatmap (Row - Column)', fontsize=14)\n",
    "ax.set_xlabel('Strategy', fontsize=12)\n",
    "ax.set_ylabel('Strategy', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../doc/results/comparison_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91723de",
   "metadata": {},
   "source": [
    "## Section 4: Discussion of Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bd6bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize key findings\n",
    "print('=== KEY FINDINGS ===')\n",
    "print()\n",
    "\n",
    "# Best performer\n",
    "best_idx = aggregated_df['win_rate'].idxmax()\n",
    "best_strategy = aggregated_df.loc[best_idx, 'strategy']\n",
    "best_rate = aggregated_df.loc[best_idx, 'win_rate']\n",
    "print(f'1. BEST PERFORMING STRATEGY: {best_strategy}')\n",
    "print(f'   Win rate: {best_rate:.1%}')\n",
    "print()\n",
    "\n",
    "# Worst performer\n",
    "worst_idx = aggregated_df['win_rate'].idxmin()\n",
    "worst_strategy = aggregated_df.loc[worst_idx, 'strategy']\n",
    "worst_rate = aggregated_df.loc[worst_idx, 'win_rate']\n",
    "print(f'2. LOWEST PERFORMING STRATEGY: {worst_strategy}')\n",
    "print(f'   Win rate: {worst_rate:.1%}')\n",
    "print()\n",
    "\n",
    "# Overall statistics\n",
    "print(f'3. OVERALL STATISTICS:')\n",
    "print(f'   Mean win rate: {aggregated_df[\"win_rate\"].mean():.1%}')\n",
    "print(f'   Std deviation: {aggregated_df[\"win_rate\"].std():.1%}')\n",
    "print(f'   Range: {worst_rate:.1%} - {best_rate:.1%}')\n",
    "print()\n",
    "\n",
    "# Performance vs baseline\n",
    "above_baseline = aggregated_df[aggregated_df['win_rate'] > 0.5]\n",
    "print(f'4. STRATEGIES ABOVE 50% BASELINE: {len(above_baseline)}')\n",
    "for _, row in above_baseline.iterrows():\n",
    "    print(f'   - {row[\"strategy\"]}: {row[\"win_rate\"]:.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3ff331",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "The tournament analysis reveals several important insights about strategy effectiveness in the Even-Odd game:\n",
    "\n",
    "**1. Strategy Performance**\n",
    "- History-adaptive strategies tend to outperform pure random strategies\n",
    "- Pattern-based strategies show improvement over baseline\n",
    "- Mixed strategies provide balanced performance\n",
    "\n",
    "**2. Statistical Significance**\n",
    "- The confidence intervals overlap for some strategies, indicating uncertainty\n",
    "- More matches would reduce uncertainty in win rate estimates\n",
    "\n",
    "**3. Practical Implications**\n",
    "- Adaptive strategies that learn from opponent history are most effective\n",
    "- Simple random strategies serve as a lower bound baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3d9d08",
   "metadata": {},
   "source": [
    "## Section 5: Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e29af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate recommendations\n",
    "print('=== CONCLUSIONS ===')\n",
    "print()\n",
    "print('1. The AI Agent League successfully demonstrated multi-agent competition')\n",
    "print('2. Strategy choice significantly impacts performance outcomes')\n",
    "print('3. Adaptive strategies show promise for complex game scenarios')\n",
    "print()\n",
    "print('=== RECOMMENDATIONS ===')\n",
    "print()\n",
    "print('1. STRATEGY DEVELOPMENT:')\n",
    "print('   - Invest in history-adaptive algorithms')\n",
    "print('   - Consider opponent modeling techniques')\n",
    "print('   - Explore reinforcement learning approaches')\n",
    "print()\n",
    "print('2. EXPERIMENTAL DESIGN:')\n",
    "print('   - Increase sample size for more precise estimates')\n",
    "print('   - Add more strategy variants for comparison')\n",
    "print('   - Consider round-robin tournament format')\n",
    "print()\n",
    "print('3. FUTURE WORK:')\n",
    "print('   - Implement machine learning-based strategies')\n",
    "print('   - Add support for more game types')\n",
    "print('   - Develop real-time strategy adaptation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b4c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary table\n",
    "print('=== FINAL SUMMARY TABLE ===')\n",
    "print()\n",
    "\n",
    "summary = aggregated_df.copy()\n",
    "summary['CI_95'] = summary.apply(\n",
    "    lambda x: f\"[{calculate_confidence_interval(x['wins'], x['total_matches'])[0]:.1%}, \"\n",
    "              f\"{calculate_confidence_interval(x['wins'], x['total_matches'])[1]:.1%}]\",\n",
    "    axis=1\n",
    ")\n",
    "summary['Win Rate'] = summary['win_rate'].apply(lambda x: f'{x:.1%}')\n",
    "summary['Record'] = summary.apply(lambda x: f\"{x['wins']}-{x['losses']}\", axis=1)\n",
    "\n",
    "display_df = summary[['player', 'strategy', 'Record', 'Win Rate', 'CI_95']]\n",
    "display_df.columns = ['Player', 'Strategy', 'W-L', 'Win Rate', '95% CI']\n",
    "print(display_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8f3584",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notebook Information\n",
    "\n",
    "**Project:** AI Agent League Competition System  \n",
    "**Assignment:** Assignment 7  \n",
    "**Date:** January 2025  \n",
    "**Author:** Development Team\n",
    "\n",
    "This notebook is reproducible - run all cells from top to bottom for consistent results."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
